import os
import json
import subprocess
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
from utils.srt_utils import generate_srt
from utils.ffmpeg_utils import get_video_duration
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

MAX_WORKERS = int(os.getenv("CLIPPER_MAX_WORKERS", 4))
FFMPEG_PATH = os.getenv("FFMPEG_PATH", "ffmpeg")

logger = logging.getLogger(__name__)

def generate_clips(video_path, clip_duration, transcript, output_dir, cache_file=None, platform=None, source_id=None, aspect_ratio="16:9"):
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"Video file not found: {video_path}")
    
    os.makedirs(output_dir, exist_ok=True)
    duration = int(parse_duration(clip_duration))
    
    print(f"üîç DEBUG: Parsed clip duration: {duration} seconds", flush=True)
    print(f"üîç DEBUG: About to call get_video_duration for: {video_path}", flush=True)
    
    try:
        total_duration = get_video_duration(video_path)
        print(f"üîç DEBUG: Video total duration: {total_duration} seconds", flush=True)
    except Exception as e:
        print(f"‚ùå ERROR: Failed to get video duration: {e}", flush=True)
        print(f"‚ùå ERROR: Exception type: {type(e).__name__}", flush=True)
        logger.error(f"Failed to get video duration: {e}")
        return []
    
    num_clips = int(total_duration // duration) + (1 if total_duration % duration > 0 else 0)
    
    # DEBUG: Limit to 1 clip for debugging purposes
    num_clips = min(num_clips, 1)
    print(f"üîç DEBUG: Calculated number of clips: {num_clips} (limited to 1 for debugging)", flush=True)

    logger.info(f"üé¨ Clip generation started - Video: {video_path}, Duration: {total_duration}s, Clip length: {duration}s, Expected clips: {num_clips}")
    logger.info(f"üìù Transcript has {len(transcript)} segments")
    
    # Debug transcript data
    if transcript:
        logger.info(f"üìä First transcript segment: {transcript[0]}")
        logger.info(f"üìä Last transcript segment: {transcript[-1]}")
    else:
        logger.warning("‚ö†Ô∏è Transcript is empty!")

    # Early return if no clips to generate
    if num_clips <= 0:
        print(f"‚ö†Ô∏è WARNING: No clips to generate (num_clips={num_clips})", flush=True)
        return []

    clips, cache = [], {}
    cache_lock = Lock()

    # Load existing cache
    if cache_file and os.path.exists(cache_file):
        try:
            with open(cache_file, "r") as f:
                cache = json.load(f)
        except json.JSONDecodeError:
            logger.warning(f"Corrupted cache file: {cache_file}, starting fresh")

    def is_valid_clip(path):
        return os.path.exists(path) and os.path.getsize(path) > 0

    def process_clip(i):
        start_time = i * duration
        actual_duration = min(duration, total_duration - start_time)
        end_time = start_time + actual_duration

        clip_name = f"clip_{i+1}.mp4"
        clip_path = os.path.join(output_dir, clip_name)
        srt_path = os.path.join(output_dir, f"clip_{i+1}.srt")

        logger.info(f"üéûÔ∏è Processing clip {i+1}: {start_time}s - {end_time}s")

        # Skip cached
        if clip_name in cache and is_valid_clip(clip_path):
            logger.info(f"‚ôªÔ∏è Using cached clip {i+1}")
            return cache[clip_name]

        clip_segments = []
        for t in transcript:
            if t["start"] < end_time and t["end"] > start_time:
                s = t.copy()
                s["start"] = max(0, t["start"] - start_time)
                s["end"] = min(actual_duration, t["end"] - start_time)
                clip_segments.append(s)

        transcript_text = " ".join([t["text"] for t in clip_segments])
        logger.info(f"üìù Clip {i+1} has {len(clip_segments)} transcript segments")

        # Extract video with aspect ratio conversion
        logger.info(f"üé¨ Extracting video clip {i+1} using FFmpeg with aspect ratio {aspect_ratio}")
        
        # Build ffmpeg command with aspect ratio conversion
        ffmpeg_cmd = [
            FFMPEG_PATH, "-ss", str(start_time), "-t", str(actual_duration),
            "-i", video_path
        ]
        
        # Add aspect ratio conversion filters
        if aspect_ratio != "16:9":  # Only add filters if not default
            # Convert aspect ratio string to decimal for calculations
            if aspect_ratio == "9:16":
                # Portrait mode - crop and scale for vertical video
                ffmpeg_cmd.extend(["-vf", "scale=1080:1920:force_original_aspect_ratio=increase,crop=1080:1920"])
            elif aspect_ratio == "4:3":
                # 4:3 aspect ratio
                ffmpeg_cmd.extend(["-vf", "scale=1440:1080:force_original_aspect_ratio=increase,crop=1440:1080"])
            elif aspect_ratio == "1:1":
                # Square aspect ratio
                ffmpeg_cmd.extend(["-vf", "scale=1080:1080:force_original_aspect_ratio=increase,crop=1080:1080"])
            else:
                # For other ratios, try to parse and apply generic scaling
                try:
                    w_ratio, h_ratio = map(int, aspect_ratio.split(':'))
                    # Use 1080p as base height and calculate width
                    target_height = 1080
                    target_width = int((target_height * w_ratio) / h_ratio)
                    ffmpeg_cmd.extend(["-vf", f"scale={target_width}:{target_height}:force_original_aspect_ratio=increase,crop={target_width}:{target_height}"])
                except:
                    logger.warning(f"‚ö†Ô∏è Invalid aspect ratio format: {aspect_ratio}, using original")
        
        # Add output parameters
        ffmpeg_cmd.extend(["-c:a", "copy", clip_path, "-y"])
        
        result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)

        if result.returncode != 0:
            logger.error(f"‚ùå FFmpeg failed for clip {i+1}: {result.stderr}")
            raise RuntimeError(f"FFmpeg failed: {result.stderr}")
        if not is_valid_clip(clip_path):
            logger.error(f"‚ùå Invalid clip generated: {clip_path}")
            raise RuntimeError(f"Invalid clip: {clip_path}")

        logger.info(f"‚úÖ Video clip {i+1} extracted successfully")

        # Generate SRT
        generate_srt(clip_segments, srt_path)
        logger.info(f"üìÑ SRT file generated for clip {i+1}")

        clip_data = {
            "index": i + 1,
            "video": clip_path,
            "srt": srt_path,
            "transcript_text": transcript_text,
            "start_time": start_time,
            "end_time": end_time,
            "platform": platform,
            "source_id": source_id,
            "title": None,  # Will be populated by viral detector
        }

        with cache_lock:
            cache[clip_name] = clip_data

        logger.info(f"üéâ Clip {i+1} processed successfully")
        return clip_data

    # Run in parallel
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_clip, i): i for i in range(num_clips)}
        for future in as_completed(futures):
            i = futures[future]
            try:
                clip_data = future.result()
                clips.append(clip_data)
            except Exception:
                logger.error(f"Failed to process clip {i+1}", exc_info=True)

    # Write final cache atomically
    if cache_file:
        tmp = cache_file + ".tmp"
        with open(tmp, "w") as f:
            json.dump(cache, f, indent=2)
        os.replace(tmp, cache_file)

    clips.sort(key=lambda x: x["index"])
    return clips


def parse_duration(value):
    value = str(value).lower().strip()
    try:
        if value.endswith("m"):
            return int(value[:-1]) * 60
        elif value.endswith("s"):
            return int(value[:-1])
        return int(value)
    except ValueError:
        raise ValueError(f"Invalid duration: {value}. Use '60', '60s', or '1m'")
